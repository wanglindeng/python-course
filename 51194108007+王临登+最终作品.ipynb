{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from pyaudio import PyAudio,paInt16\n",
    "from threading import Timer\n",
    "import time\n",
    "\n",
    "framerate=8000\n",
    "NUM_SAMPLES=2000\n",
    "channels=1\n",
    "sampwidth=2\n",
    "TIME=2\n",
    "def save_wave_file(filename,data):\n",
    "    '''save the date to the wavfile'''\n",
    "    wf=wave.open(filename,'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(sampwidth)\n",
    "    wf.setframerate(framerate)\n",
    "    wf.writeframes(b\"\".join(data))\n",
    "    wf.close()\n",
    "\n",
    "def my_record():\n",
    "    pa=PyAudio()\n",
    "    stream=pa.open(format = paInt16,channels=1,\n",
    "                   rate=framerate,input=True,\n",
    "                   frames_per_buffer=NUM_SAMPLES)\n",
    "    my_buf=[]\n",
    "    count=0\n",
    "    print(\"录音开始，请说话！\")\n",
    "    while count<TIME*15:#控制录音时间\n",
    "        string_audio_data = stream.read(NUM_SAMPLES)\n",
    "        my_buf.append(string_audio_data)\n",
    "        count+=1\n",
    "        print('.')\n",
    "    print(\"录音结束，请停止说话！\")\n",
    "    print('\\n\\n')\n",
    "    save_wave_file('01.wav',my_buf)\n",
    "    stream.close()\n",
    "\n",
    "chunk=2014\n",
    "def play():\n",
    "    wf=wave.open(r\"01.wav\",'rb')\n",
    "    p=PyAudio()\n",
    "    stream=p.open(format=p.get_format_from_width(wf.getsampwidth()),channels=\n",
    "    wf.getnchannels(),rate=wf.getframerate(),output=True)\n",
    "    while True:\n",
    "        data=wf.readframes(chunk)\n",
    "        if data==\"\":break\n",
    "        stream.write(data)\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luyin():\n",
    "    if __name__ == '__main__':\n",
    "        my_record()\n",
    "        time.sleep(4)\n",
    "        print(\"现在开始播放录音：\")\n",
    "        time.sleep(2)\n",
    "        play()\n",
    "        time.sleep(15)\n",
    "        print(\"录音播放结束！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pyttsx3\n",
    "\n",
    "def wenzi():\n",
    "    str = input(\"请输入：\");\n",
    "    print (\"你输入的内容是: \", str)\n",
    "    with open( 'wenzi.txt', 'r',encoding=\"utf-8\" ) as f:\n",
    "        ff=f.read()\n",
    "    text=str\n",
    "    voice=pyttsx3.init()\n",
    "    voice.say(text)\n",
    "    voice.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请选择您要执行的操作：\n",
      "\n",
      "1:文字识别 \b   2:语音识别 \b \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(\"请选择您要执行的操作：\\n\")\n",
    "print(\"1:文字识别 \\b   2:语音识别 \\b \")\n",
    "k = input(\"请输入: \")\n",
    "\n",
    "if k == '1':  # 调用函数文字转语音\n",
    "    wenzi_yuyin()\n",
    "elif k== '2':  # 调用函数语音转文字\n",
    "    luyin() \n",
    "else:\n",
    "    print(\"您输入的数字有误，请重新输入！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!Background Captured!!!\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "!!!Reset BackGround!!!\n",
      "!!!Background Captured!!!\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "!!!Reset BackGround!!!\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "# coding=utf-8\n",
    "import pyttsx3\n",
    "import wave\n",
    "from pyaudio import PyAudio,paInt16\n",
    "from threading import Timer\n",
    "import time\n",
    "import cv2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import win32api\n",
    "import win32con\n",
    "\n",
    "def shoushishibie():\n",
    "    # 参数\n",
    "    cap_region_x_begin = 0.5  # 起点/总宽度\n",
    "    cap_region_y_end = 0.8\n",
    "    threshold = 60  # 二值化阈值\n",
    "    blurValue = 41  # 高斯模糊参数\n",
    "    bgSubThreshold = 50\n",
    "    learningRate = 0\n",
    "\n",
    "    # 变量\n",
    "    isBgCaptured = 0  # 布尔类型, 背景是否被捕获\n",
    "    triggerSwitch = False  # 如果正确，键盘模拟器将工作\n",
    "\n",
    "\n",
    "    def printThreshold(thr):\n",
    "        print(\"! Changed threshold to \" + str(thr))\n",
    "\n",
    "\n",
    "    def removeBG(frame): #移除背景\n",
    "        fgmask = bgModel.apply(frame, learningRate=learningRate) #计算前景掩膜\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        fgmask = cv2.erode(fgmask, kernel, iterations=1) #使用特定的结构元素来侵蚀图像。\n",
    "        res = cv2.bitwise_and(frame, frame, mask=fgmask) #使用掩膜移除静态背景\n",
    "        return res\n",
    "\n",
    "    # 相机/摄像头\n",
    "    camera = cv2.VideoCapture(0)   #打开电脑自带摄像头，如果参数是1会打开外接摄像头\n",
    "    camera.set(10, 200)   #设置视频属性\n",
    "    cv2.namedWindow('trackbar') #设置窗口名字\n",
    "    cv2.resizeWindow(\"trackbar\", 640, 200)  #重新设置窗口尺寸\n",
    "    cv2.createTrackbar('threshold', 'trackbar', threshold, 100, printThreshold)\n",
    "    #createTrackbar是Opencv中的API，其可在显示图像的窗口中快速创建一个滑动控件，用于手动调节阈值，具有非常直观的效果。\n",
    "\n",
    "    while camera.isOpened():\n",
    "        ret, frame = camera.read()\n",
    "        threshold = cv2.getTrackbarPos('threshold', 'trackbar') #返回滑动条上的位置的值（即实时更新阈值）\n",
    "        # frame = cv2.cvtColor(frame,cv2.COLOR_RGB2YCrCb)\n",
    "        frame = cv2.bilateralFilter(frame, 5, 50, 100)  # 双边滤波\n",
    "        frame = cv2.flip(frame, 1)  # 翻转  0:沿X轴翻转(垂直翻转)   大于0:沿Y轴翻转(水平翻转)   小于0:先沿X轴翻转，再沿Y轴翻转，等价于旋转180°\n",
    "        cv2.rectangle(frame, (int(cap_region_x_begin * frame.shape[1]), 0),(frame.shape[1], int(cap_region_y_end * frame.shape[0])), (0, 0, 255), 2)\n",
    "        #画矩形框  frame.shape[0]表示frame的高度    frame.shape[1]表示frame的宽度   注：opencv的像素是BGR顺序\n",
    "        cv2.imshow('original', frame)   #经过双边滤波后的初始化窗口\n",
    "    \n",
    "        #主要操作\n",
    "        if isBgCaptured == 1:  # isBgCaptured == 1 表示已经捕获背景\n",
    "            img = removeBG(frame)  #移除背景\n",
    "            img = img[0:int(cap_region_y_end * frame.shape[0]),int(cap_region_x_begin * frame.shape[1]):frame.shape[1]]  # 剪切右上角矩形框区域\n",
    "            cv2.imshow('mask', img)\n",
    "    \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  #将移除背景后的图像转换为灰度图\n",
    "            blur = cv2.GaussianBlur(gray, (blurValue, blurValue), 0)  #加高斯模糊\n",
    "            cv2.imshow('blur', blur)\n",
    "            ret, thresh = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY)  #二值化处理\n",
    "            cv2.imshow('binary', thresh)\n",
    "\n",
    "            # get the coutours\n",
    "            thresh1 = copy.deepcopy(thresh)\n",
    "            contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "            #寻找轮廓   注：这里的'_'用作变量名称，_表示一个变量被指定了名称，但不打算使用。\n",
    "            length = len(contours)\n",
    "            maxArea = -1\n",
    "            if length > 0:\n",
    "                for i in range(length):  # 找到最大的轮廓（根据面积）\n",
    "                    temp = contours[i]\n",
    "                    area = cv2.contourArea(temp)  #计算轮廓区域面积\n",
    "                    if area > maxArea:\n",
    "                        maxArea = area\n",
    "                        ci = i\n",
    "\n",
    "                res = contours[ci]  #得出最大的轮廓区域\n",
    "                hull = cv2.convexHull(res)  #得出点集（组成轮廓的点）的凸包\n",
    "                drawing = np.zeros(img.shape, np.uint8)\n",
    "                cv2.drawContours(drawing, [res], 0, (0, 255, 0), 2)   #画出最大区域轮廓\n",
    "                cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 3)  #画出凸包轮廓\n",
    "\n",
    "                moments = cv2.moments(res)  # 求最大区域轮廓的各阶矩\n",
    "                center = (int(moments['m10'] / moments['m00']), int(moments['m01'] / moments['m00']))\n",
    "                cv2.circle(drawing, center, 8, (0,0,255), -1)   #画出重心\n",
    "\n",
    "                fingerRes = []   #寻找指尖\n",
    "                max = 0; count = 0; notice = 0; cnt = 0\n",
    "                for i in range(len(res)):\n",
    "                    temp = res[i]\n",
    "                    dist = (temp[0][0] -center[0])*(temp[0][0] -center[0]) + (temp[0][1] -center[1])*(temp[0][1] -center[1]) #计算重心到轮廓边缘的距离\n",
    "                    if dist > max:\n",
    "                        max = dist\n",
    "                        notice = i\n",
    "                    if dist != max:\n",
    "                        count = count + 1\n",
    "                        if count > 40:\n",
    "                            count = 0\n",
    "                            max = 0\n",
    "                            flag = False   #布尔值\n",
    "                            if center[1] < res[notice][0][1]:   #低于手心的点不算\n",
    "                                continue\n",
    "                            for j in range(len(fingerRes)):  #离得太近的不算\n",
    "                                if abs(res[notice][0][0]-fingerRes[j][0]) < 20 :\n",
    "                                    flag = True\n",
    "                                    break\n",
    "                            if flag :\n",
    "                                continue\n",
    "                            fingerRes.append(res[notice][0])\n",
    "                            cv2.circle(drawing, tuple(res[notice][0]), 8 , (255, 0, 0), -1) #画出指尖\n",
    "                            cv2.line(drawing, center, tuple(res[notice][0]), (255, 0, 0), 2)\n",
    "                            cnt = cnt + 1\n",
    "\n",
    "                cv2.imshow('output', drawing)\n",
    "                print(cnt)\n",
    "                if triggerSwitch is True:\n",
    "                    if cnt >= 3:\n",
    "                        print(cnt)\n",
    "                        # app('System Events').keystroke(' ')  # simulate pressing blank space\n",
    "                        win32api.keybd_event(32, 0, 0, 0)  # 空格键位码是32\n",
    "                        win32api.keybd_event(32, 0, win32con.KEYEVENTF_KEYUP, 0)  # 释放空格键\n",
    "\n",
    "        # 输入的键盘值\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 2:  # 按下ESC退出\n",
    "            break\n",
    "        elif k == ord('b'):  # 按下'b'背景\n",
    "            bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)\n",
    "            #Opencv集成了BackgroundSubtractorMOG2用于动态目标检测，用到的是基于自适应混合高斯背景建模的背景减除法。\n",
    "            isBgCaptured = 1\n",
    "            print('!!!Background Captured!!!')\n",
    "        elif k == ord('r'):  # 按下'r'会重置背景\n",
    "            bgModel = None\n",
    "            triggerSwitch = False\n",
    "            isBgCaptured = 0\n",
    "            print('!!!Reset BackGround!!!')\n",
    "        elif k == ord('n'):\n",
    "            triggerSwitch = True\n",
    "            print('!!!Trigger On!!!')\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "framerate=8000\n",
    "NUM_SAMPLES=2000\n",
    "channels=1\n",
    "sampwidth=2\n",
    "TIME=2\n",
    "def save_wave_file(filename,data):\n",
    "    '''save the date to the wavfile'''\n",
    "    wf=wave.open(filename,'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(sampwidth)\n",
    "    wf.setframerate(framerate)\n",
    "    wf.writeframes(b\"\".join(data))\n",
    "    wf.close()\n",
    "\n",
    "def my_record():\n",
    "    pa=PyAudio()\n",
    "    stream=pa.open(format = paInt16,channels=1,\n",
    "                   rate=framerate,input=True,\n",
    "                   frames_per_buffer=NUM_SAMPLES)\n",
    "    my_buf=[]\n",
    "    count=0\n",
    "    print(\"Recording begins, please speak！\")\n",
    "    while count<TIME*15:#控制录音时间\n",
    "        string_audio_data = stream.read(NUM_SAMPLES)\n",
    "        my_buf.append(string_audio_data)\n",
    "        count+=1\n",
    "        print('.')\n",
    "    print(\"Stop recording, please stop talking！\")\n",
    "    print('\\n\\n')\n",
    "    save_wave_file('01.wav',my_buf)\n",
    "    stream.close()\n",
    "\n",
    "chunk=2014\n",
    "def play():\n",
    "    wf=wave.open(r\"01.wav\",'rb')\n",
    "    p=PyAudio()\n",
    "    stream=p.open(format=p.get_format_from_width(wf.getsampwidth()),channels=\n",
    "    wf.getnchannels(),rate=wf.getframerate(),output=True)\n",
    "    while True:\n",
    "        data=wf.readframes(chunk)\n",
    "        if data==\"\":break\n",
    "        stream.write(data)\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "def luyin():\n",
    "    if __name__ == '__main__':\n",
    "        my_record()\n",
    "        time.sleep(4)\n",
    "        print(\"Start recording now：\")\n",
    "        time.sleep(2)\n",
    "        play()\n",
    "        time.sleep(15)\n",
    "        print(\"Recording ends！\")\n",
    "\n",
    "def wenzi():\n",
    "    str = input(\"please enter：\");\n",
    "    print (\"What you enter is: \", str)\n",
    "    with open( 'wenzi.txt', 'r',encoding=\"utf-8\" ) as f:\n",
    "        ff=f.read()\n",
    "    text=str\n",
    "    voice=pyttsx3.init()\n",
    "    voice.say(text)\n",
    "    voice.runAndWait()\n",
    "    \n",
    "def run1():\n",
    "    wenzi()\n",
    "\n",
    "def run2():\n",
    "    luyin()\n",
    "\n",
    "def run3():\n",
    "    shoushishibie()\n",
    "    \n",
    "root = Tk()\n",
    "root.geometry('720x480')\n",
    "root.title('Welcome to python game')\n",
    "\n",
    "lb1 = Label(root,text='Please select the game you want to play：',font=('华文新魏',20))\n",
    "lb1.place(relx=0.1, rely=0.1, relwidth=0.8, relheight=0.1)\n",
    "\n",
    "# 方法-直接调用 run1()\n",
    "btn1 = Button(root, text='Text recognition',fg = \"white\", bg = \"black\", command=run1)\n",
    "btn1.place(relx=0.35, rely=0.3, relwidth=0.3, relheight=0.1)#relx、rely代表组件相当于父容器的x、y的坐标，0.0代表左边缘，1.0代表右边缘\n",
    "#relwidth, relheight 代表组件相对于父容器的宽度、高度。\n",
    "\n",
    "# 方法二利用 lambda 传参数调用run2()\n",
    "btn2 = Button(root, text='Speech Recognition',fg = \"white\", bg = \"black\",command=run2)\n",
    "btn2.place(relx=0.35, rely=0.5, relwidth=0.3, relheight=0.1)\n",
    "\n",
    "btn3 = Button(root, text='Gesture Recognition',fg = \"white\", bg = \"black\",command=run3)\n",
    "btn3.place(relx=0.35, rely=0.7, relwidth=0.3, relheight=0.1)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
